---
permalink: /
title: 
excerpt: 
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, this is Zhe Li. I am a final-year (2019~) Ph.D. student in Department of Automation, Tsinghua University, advised by Prof. [Yebin Liu](http://www.liuyebin.com/).
My research focuses on **human-centric 3D vision**, including 3D human reconstruction, animation and generation, etc.


## Background

<div align="left">
<table style="width:100%;border:none;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<tr>
<td style="padding:20px;width:25%;vertical-align:middle;border:none">
<img align="center" width="80" src="../images/tsinghua.png"/> 
</td>
<td style="padding:20px;width:75%;vertical-align:middle;border: none">
Ph.D. Student. Sep. 2019 - Jun. 2024 (Expected)<br>
<a href="http://www.au.tsinghua.edu.cn/">Department of Automation</a><br>
<a href="https://www.tsinghua.edu.cn/en/index.html">Tsinghua University</a><br>
</td>
</tr>
<tr>
<td style="padding:20px;width:25%;vertical-align:middle;border:none">
<img align="center" width="80" src="../images/ustc.png"/> 
</td>
<td style="padding:20px;width:75%;vertical-align:middle;border: none">
Bachelor of Engineering. Sep. 2015 - Jun. 2019<br>
<a href="https://sgy.ustc.edu.cn/"><b>Class of the Gifted Young (少年班)</b></a><br>
<a href="http://en.ustc.edu.cn/">University of Science and Technology of China</a><br>
</td>
</tr>
</table>    
</div>


## Research

<img align="left" width="215" src="../images/ani_gaussians.gif" style="padding-right:20px; padding-top:20px"/>

<b>Animatable Gaussians: Learning Pose-dependent Gaussian Maps for High-fidelity Human Avatar Modeling</b><br>
<b>Zhe Li</b>, Zerong Zheng, Lizhen Wang, Yebin Liu<br>
arXiv, 2023<br>
[<i class="fas fa-fw fa-globe"></i>Projectpage](https://animatable-gaussians.github.io/) /
[<i class="fas fa-fw fa-file-pdf"></i>Paper](https://arxiv.org/pdf/2311.16096.pdf) /
[<i class="fas fa-fw fa-video"></i>Video](https://www.youtube.com/watch?v=kOmZxD0HxZI) /
[<i class="fab fa-fw fa-github fa-github"></i>Code](https://github.com/lizhe00/AnimatableGaussians)<br>

---

<img align="left" width="215" height="110" src="../images/gaussianhead.jpg" style="padding-right:20px; padding-top:20px"/>

<b>Gaussian Head Avatar: Ultra High-fidelity Head Avatar via Dynamic Gaussians</b><br>
Yuelang Xu, Benwang Chen, <b>Zhe Li</b>, Hongwen Zhang, Lizhen Wang, Zerong Zheng, Yebin Liu<br>
arXiv, 2023<br>
[<i class="fas fa-fw fa-globe"></i>Projectpage](https://yuelangx.github.io/gaussianheadavatar/) /
[<i class="fas fa-fw fa-file-pdf"></i>Paper](https://arxiv.org/abs/2312.03029.pdf) /
[<i class="fas fa-fw fa-video"></i>Video](https://www.youtube.com/watch?v=kvrrI3EoM5g) /
[<i class="fab fa-fw fa-github fa-github"></i>Code](https://github.com/YuelangX/Gaussian-Head-Avatar)<br>

---

<img align="left" width="215" height="110" src="../images/sig23_posevocab.jpg" style="padding-right:20px; padding-top:20px"/>

<b>PoseVocab: Learning Joint-structured Pose Embeddings for Human Avatar Modeling</b><br>
<b>Zhe Li</b>, Zerong Zheng, Yuxiao Liu, Boyao Zhou, Yebin Liu<br>
<i><b>SIGGRAPH</b> Conference Proceedings, 2023</i><br>
[<i class="fas fa-fw fa-globe"></i>Projectpage](https://lizhe00.github.io/projects/posevocab) /
[<i class="fas fa-fw fa-file-pdf"></i>Paper](https://arxiv.org/pdf/2304.13006.pdf) /
[<i class="fas fa-fw fa-video"></i>Video](https://youtu.be/L-kg74A6yNc) /
[<i class="fab fa-fw fa-github fa-github"></i>Code](https://github.com/lizhe00/PoseVocab)<br>

---

<img align="left" width="215" height="110" src="../images/eccv22_avatarcap.jpg" style="padding-right:20px; padding-top:20px"/>

<b>AvatarCap: Animatable Avatar Conditioned Monocular Human Volumetric Capture</b><br>
<b>Zhe Li</b>, Zerong Zheng, Hongwen Zhang, Chaonan Ji, Yebin Liu<br>
<i>European Conference on Computer Vision (<b>ECCV</b>), 2022</i><br>
[<i class="fas fa-fw fa-globe"></i>Projectpage](http://www.liuyebin.com/avatarcap/avatarcap.html) /
[<i class="fas fa-fw fa-file-pdf"></i>Paper](https://arxiv.org/pdf/2207.02031.pdf) /
[<i class="fas fa-fw fa-video"></i>Video](http://www.liuyebin.com/avatarcap/assets/supp_video.mp4) /
[<i class="fab fa-fw fa-github fa-github"></i>Code](https://github.com/lizhe00/AvatarCap)<br>

---

<img align="left" width="215" height="110" src="../images/tpami21_portrait.jpg" style="padding-right:20px; padding-top:20px"/>

<b>Robust and Accurate 3D Self-portraits in Seconds</b><br>
<b>Zhe Li</b>, Tao Yu, Zerong Zheng, Yebin Liu<br>
<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>), 2021</i><br>
[<i class="fas fa-fw fa-file-pdf"></i>Paper](https://ieeexplore.ieee.org/document/9540284/) /
[<i class="fas fa-fw fa-database"></i>Dataset (Please email me)](mailto:liz19@mails.tsinghua.edu.cn)<br>

---

<img align="left" width="215" height="110" src="../images/iccv21_lwtotalcap.jpg" style="padding-right:20px; padding-top:20px"/>

<b>Lightweight Multi-person Total Motion Capture Using Sparse Multi-view Cameras</b><br>
Yuxiang Zhang, <b>Zhe Li</b>, Liang An, Mengcheng Li, Tao Yu, Yebin Liu<br>
<i>IEEE International Conference on Computer Vision (<b>ICCV</b>), 2021</i><br>
[<i class="fas fa-fw fa-globe"></i>Projectpage](http://www.liuyebin.com/lwtotalcap/lwtotalcap.html) /
[<i class="fas fa-fw fa-file-pdf"></i>Paper](https://arxiv.org/pdf/2108.10378.pdf) /
[<i class="fas fa-fw fa-video"></i>Video](http://www.liuyebin.com/lwtotalcap/assets/video.mp4)<br>

---

<img align="left" width="215" height="110" src="../images/cvpr21_posefusion.jpg" style="padding-right:20px; padding-top:20px"/>

<b>POSEFusion: Pose-guided Selective Fusion for Single-view Human Volumetric Capture</b><br>
<b>Zhe Li</b>, Tao Yu, Zerong Zheng, Kaiwen Guo, Yebin Liu<br>
<i>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021</i>  <font color="#dd0000">(Oral presentation)</font><br>
[<i class="fas fa-fw fa-globe"></i>Projectpage](http://www.liuyebin.com/posefusion/posefusion.html) /
[<i class="fas fa-fw fa-file-pdf"></i>Paper](https://arxiv.org/pdf/2103.15331.pdf) /
[<i class="fas fa-fw fa-video"></i>Video](http://www.liuyebin.com/posefusion/assets/supp_video.mp4) /
[<i class="fas fa-fw fa-video"></i>Talk](https://youtu.be/34jrPLkiPrw)<br>

---

<img align="left" width="215" height="110" src="../images/cvpr20_portrait.jpg" style="padding-right:20px; padding-top:20px"/>

<b>Robust 3D Self-portraits in Seconds</b><br>
<b>Zhe Li</b>, Tao Yu, Chuanyu Pan, Zerong Zheng, Yebin Liu<br>
<i>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020</i>  <font color="#dd0000">(Oral presentation)</font><br>
[<i class="fas fa-fw fa-globe"></i>Projectpage](http://www.liuyebin.com/portrait/portrait.html) /
[<i class="fas fa-fw fa-file-pdf"></i>Paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Robust_3D_Self-Portraits_in_Seconds_CVPR_2020_paper.pdf) /
[<i class="fas fa-fw fa-video"></i>Video](http://www.liuyebin.com/portrait/assets/portrait.mp4) /
[<i class="fas fa-fw fa-video"></i>Talk](https://youtu.be/nx-pzk12hLY)<br>

## Award
+ Tsinghua Kuaishou Scholarship, Tsinghua University, 2023
+ Tsinghua Alumni Li Yanda Scholarship, Tsinghua University, 2022
+ <b>National Scholarship</b>, Ministry of Education of China, 2021

## Contact
E-mail: liz19 AT mails.tsinghua.edu.cn<br>
WeChat: nexus_unite